exp_name: "basic_1"
optim:
    name: "adam"
    lr: 0.001
    wd: 0.000001
sched: "exp" #scheduler; either None of cosine decay
pretrained: False #True or False
lr_scale: 10 # Used only for pretrained, in case you want to downscale backbone weight
transf: # None or  "Basic"
batch_size: 64
epochs: 100
mixup: 0
    
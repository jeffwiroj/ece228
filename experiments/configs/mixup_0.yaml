exp_name: "mixup_0"
optim:
    name: "adam"
    lr: 0.0001
    wd: 0.00001
sched: #scheduler; either None or exp
pretrained: False #True or False
lr_scale: 10 # Used only for pretrained, in case you want to downscale backbone weight
transf: "basic" # None or  "basic"
batch_size: 512
epochs: 100
mixup: 0.4

    